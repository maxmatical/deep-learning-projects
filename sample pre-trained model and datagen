from keras import models
from keras import layers
from keras import optimizers
from keras.applications import VGG16
from keras.applications import InceptionResNetV2
import sys
import os
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense, Activation
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras import callbacks
from keras.models import load_model
import matplotlib.pyplot as plt 


train_data_path = 'train'
validation_data_path = 'validation'

img_width, img_height = 150, 150


# Loading inceptionResnetv2
incep_res_v2 = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))
# Finrtuning all the layeers
for layer in incep_res_v2 .layers[1:]:
    layer.trainable = False

# Check the trainable status of the individual layers
for layer in incep_res_v2 .layers:
    print(layer, layer.trainable)

# Create the model
model = models.Sequential()

# Add the convolutional base model
model.add(incep_res_v2)

# Add new layers
model.add(layers.Flatten())
model.add(layers.Dense(1024, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(12, activation='sigmoid'))

# Show a summary of the model. Check the number of trainable parameters
model.summary()
#model = load_model('incep_res_v2_new.h5')
train_datagen = ImageDataGenerator(
      rescale=1./255,
      rotation_range=20,
      width_shift_range=0.2,
      height_shift_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

validation_datagen = ImageDataGenerator(rescale=1./255)

train_batchsize = 512
val_batchsize = 512

train_generator = train_datagen.flow_from_directory(
        train_data_path,
        target_size=(img_width, img_height),
        batch_size=train_batchsize,
        class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
        validation_data_path,
        target_size=(img_width, img_height),
        batch_size=val_batchsize,
        class_mode='categorical',
        shuffle=False)

# Compile the model
model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-4,clipvalue=0.5),
              metrics=['acc'])

#class_weights = {0: 4, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 4, 7: 2, 8: 4, 9: 2, 10: 6, 11: 1}
# Train the model
history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=8,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples/validation_generator.batch_size,
      verbose=1)

# Save the model
model.save('incep_res_v2_new1.h5')

# loss and accuracy curves.
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training acc')
plt.plot(epochs, val_acc, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()
